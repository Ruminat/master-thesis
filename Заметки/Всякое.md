#### Введение

- Вода
- Различные задачи NLP, их статус-кво
- Генерация текста, чё каво там
- О чём моя работа: цели, задачи

#### Описание предметной области

- Сложности обработки языков (русский, японский)
- Чё каво в различных задачах NLP, существующие решения
- Ну это, это самое, дядя

Про что писать, значит, буду:
- NHK easy news




#### Мысли

Автоматическое упрощение текстов нацелено на понижение сложности слов и выражений, сохраняя при этом исходный смысл текста.


- BLEU (Papineni et al., 2012), borrowed from Machine Translation. This metric is not one without problems for different text generation tasks. However, simplification studies (Stajner et al., 2014; Wubben et al., 2012; Xu et al., 2016) have shown that it correlates with human judgments of grammaticality and meaning preservation. BLEU is not well suited, though, for assessing simplicity from a lexical (Xu et al., 2016) nor a structural (Sulem et al., 2018b) point of view.

- SARI (Xu et al., 2016) is a lexical simplicity metric that measures “how good” are the words added, deleted and kept by a simplification model. The metric compares the model’s output to multiple simplification references and the original sentence. SARI has shown high correlation with human judgements of simplicity gain (Xu et al., 2016). Currently, this is the main metric used for evaluating sentence simplification models.


[JP wiki dump](https://dumps.wikimedia.org/jawiki/latest/jawiki-latest-pages-articles.xml.bz)


#### Либы

Япона-мать:
  - MeCab — токенизация
